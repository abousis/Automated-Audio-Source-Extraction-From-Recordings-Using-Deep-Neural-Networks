{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8528,
     "status": "ok",
     "timestamp": 1620545758524,
     "user": {
      "displayName": "Angelos Bousis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheIG7Oym86JUInFFmwiQbdPFioS3m4brif2cRQTg=s64",
      "userId": "15262573047553457208"
     },
     "user_tz": -180
    },
    "id": "YTfiK38glZC0",
    "outputId": "decd8bbd-74c0-461f-e6fc-d1c38e9136ba"
   },
   "outputs": [],
   "source": [
    "# Installing libraries\n",
    "!pip install musdb\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4596,
     "status": "ok",
     "timestamp": 1620545770897,
     "user": {
      "displayName": "Angelos Bousis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheIG7Oym86JUInFFmwiQbdPFioS3m4brif2cRQTg=s64",
      "userId": "15262573047553457208"
     },
     "user_tz": -180
    },
    "id": "m84bSZCvkIAU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import musdb\n",
    "import librosa\n",
    "import random\n",
    "import tensorflow.keras\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30930,
     "status": "ok",
     "timestamp": 1620545802499,
     "user": {
      "displayName": "Angelos Bousis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheIG7Oym86JUInFFmwiQbdPFioS3m4brif2cRQTg=s64",
      "userId": "15262573047553457208"
     },
     "user_tz": -180
    },
    "id": "-h9eUsSUWuv2",
    "outputId": "b990b3c2-c70e-4c08-8f4c-5c54686483a2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148071,
     "status": "ok",
     "timestamp": 1620545947311,
     "user": {
      "displayName": "Angelos Bousis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheIG7Oym86JUInFFmwiQbdPFioS3m4brif2cRQTg=s64",
      "userId": "15262573047553457208"
     },
     "user_tz": -180
    },
    "id": "nIIy9ktUphHi",
    "outputId": "8ba0d336-6771-4e9b-bb17-54274515d6ee"
   },
   "outputs": [],
   "source": [
    "# Import DATABASE\n",
    "\n",
    "# %cd ..\n",
    "# !ls\n",
    "!gsutil -m cp -r \"path-to-musdb18-on-gdrive\" \"/root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1170,
     "status": "ok",
     "timestamp": 1620545950226,
     "user": {
      "displayName": "Angelos Bousis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheIG7Oym86JUInFFmwiQbdPFioS3m4brif2cRQTg=s64",
      "userId": "15262573047553457208"
     },
     "user_tz": -180
    },
    "id": "sNDkr2NUw-Du"
   },
   "outputs": [],
   "source": [
    "class generator(tensorflow.keras.utils.Sequence):\n",
    "  def __init__(self, steps_per_epoch, tracks_in_batch, subsets, split):\n",
    "    self.steps_per_epoch = steps_per_epoch\n",
    "    self.tracks_in_batch = tracks_in_batch\n",
    "    self.subsets = subsets\n",
    "    self.split = split\n",
    "    self.mus = musdb.DB(root='../../root/musdb18', subsets=subsets, split=split)\n",
    "    self.track_number = np.arange(len(self.mus))\n",
    "    np.random.shuffle(self.track_number)\n",
    "    self.cur_index = 0    \n",
    "    self.freq_bins = 2049\n",
    "    self.num_frames = 9\n",
    "    self.num_ft_bins = self.freq_bins * self.num_frames #18441\n",
    "    self.medium_frame = int(np.floor(self.num_frames/2)) #4\n",
    "    self.hop_num_frames = 8\n",
    "    self.chunk_per_track = 323\n",
    "    self.duration = 30 # 30 sec track chunks\n",
    "    self.pad_zero = np.float32(np.zeros((self.freq_bins, self.medium_frame))) #Zero padding for IBM\n",
    "    self.pad_min = np.float32(np.zeros((self.freq_bins, self.medium_frame))) #Minimum padding for frames overlapping\n",
    "    self.mixture_train_data = np.float32(np.zeros((self.num_ft_bins, self.chunk_per_track)))\n",
    "    self.ibm_train_label = np.float32(np.zeros((self.num_ft_bins, self.chunk_per_track)))\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.steps_per_epoch\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    mixes = []\n",
    "    targets = []\n",
    "    #Random mixing batches\n",
    "    for i in range(self.tracks_in_batch):\n",
    "      mix, target_vocals = self.get_random_track_piece()\n",
    "      if self.is_source_silent(mix):\n",
    "        continue\n",
    "      track_resampled = librosa.core.resample(mix, orig_sr=44100,target_sr=22050) #Resample to 22050 Hz\n",
    "      mixture_ft_magn = np.float32(np.abs(librosa.stft(track_resampled, n_fft=4096, hop_length=256, win_length=1024, window='hann'))) \n",
    "      self.pad_min[:,:] = np.float32(min(mixture_ft_magn.min(0)))\n",
    "      mixture_padded = np.concatenate((self.pad_min, mixture_ft_magn, self.pad_min), axis=1)\n",
    "      # Append vocals\n",
    "      vocals_resampled = librosa.core.resample(target_vocals, orig_sr=44100, target_sr=22050)\n",
    "      vocals_ft_magn = np.float32(np.abs(librosa.stft(vocals_resampled, n_fft=4096, hop_length=256, win_length=1024, window='hann')))\n",
    "      # Create Binary Mask\n",
    "      ideal_binary_mask = (vocals_ft_magn > mixture_ft_magn).astype('float32')\n",
    "\n",
    "      # Concatenation for frame overlapping\n",
    "      ibm_padded = np.concatenate((self.pad_zero, ideal_binary_mask, self.pad_zero),axis=1)\n",
    "      for j in range(self.chunk_per_track):\n",
    "                start_index = j*self.hop_num_frames\n",
    "                end_index = start_index + self.num_frames\n",
    "                self.mixture_train_data[:,j:j+1] = np.reshape(mixture_padded[:,start_index:end_index],(self.num_ft_bins,1), order=\"F\")\n",
    "                self.ibm_train_label[:,j:j+1] = np.reshape(ibm_padded[:,start_index:end_index],(self.num_ft_bins,1), order=\"F\")\n",
    "\n",
    "      mixes = mixes + list(np.transpose(self.mixture_train_data))\n",
    "      targets = targets + list(np.transpose(self.ibm_train_label))\n",
    "      mix_batch = np.array(mixes)\n",
    "      target_batch = np.array(targets)\n",
    "      return mix_batch, target_batch\n",
    "\n",
    "  def get_random_track_piece(self):\n",
    "    # Getting random track\n",
    "    random.seed(int(time()%1*6000))\n",
    "    if self.cur_index == self.track_number.shape[0]:\n",
    "        np.random.shuffle(self.track_number)\n",
    "        self.cur_index = 0\n",
    "    track = self.mus[self.track_number[self.cur_index]]\n",
    "    self.cur_index += 1\n",
    "    # Getting random track chunk of given duration\n",
    "    track.chunk_duration = self.duration\n",
    "    track.chunk_start = random.uniform(0, track.duration - track.chunk_duration)\n",
    "    mix = track.audio.T\n",
    "    vocals = track.targets['vocals'].audio.T\n",
    "    # Random swapping channels\n",
    "    channel = random.randint(0, mix.shape[0]-1)\n",
    "    return mix[channel], vocals[channel]\n",
    "\n",
    "  def is_source_silent(self, source):\n",
    "    # Returns true if the parameter source is fully silent\n",
    "    return not np.any(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1620545957560,
     "user": {
      "displayName": "Angelos Bousis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheIG7Oym86JUInFFmwiQbdPFioS3m4brif2cRQTg=s64",
      "userId": "15262573047553457208"
     },
     "user_tz": -180
    },
    "id": "GmcbKakaqDov"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4367,
     "status": "ok",
     "timestamp": 1620545972018,
     "user": {
      "displayName": "Angelos Bousis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheIG7Oym86JUInFFmwiQbdPFioS3m4brif2cRQTg=s64",
      "userId": "15262573047553457208"
     },
     "user_tz": -180
    },
    "id": "Yuel4zXbqIVu"
   },
   "outputs": [],
   "source": [
    "# Creating model\n",
    "inputs = layers.Input(shape=(18441))\n",
    "x = layers.Reshape(target_shape=[9,2049,1])(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3,12), kernel_initializer='glorot_uniform', use_bias=True, bias_initializer=tf.constant_initializer(0.1), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(3,12), use_bias=True, bias_initializer=tf.constant_initializer(0.1), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(1,12), padding='same')(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(3,12), use_bias=True, bias_initializer=tf.constant_initializer(0.1), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3,12), use_bias=True, bias_initializer=tf.constant_initializer(0.1), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D(pool_size=(1,12), padding='same')(x)\n",
    "x = layers.Dropout(rate=0.5)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(2048, use_bias=True, bias_initializer=tf.constant_initializer(0.1), activation='relu')(x)\n",
    "x = layers.Dropout(rate=0.5)(x)\n",
    "x = layers.Dense(512, use_bias=True, bias_initializer=tf.constant_initializer(0.1), activation='relu')(x)\n",
    "outputs = layers.Dense(18441, use_bias=True, bias_initializer=tf.constant_initializer(0.1), activation='sigmoid')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCDuPh0Svh_M",
    "outputId": "25bf5ea2-61d8-4ada-cc87-a7eb99aeb33e"
   },
   "outputs": [],
   "source": [
    "TIB = 8 # Tracks in batch for random mixing\n",
    "EPOCHS = 15 # Total epochs\n",
    "SPE = 2000 # Steps per epoch\n",
    "\n",
    "print('<--[INFO] creating batch generators...')\n",
    "train_gen = generator(SPE, TIB, 'train', 'train')\n",
    "valid_gen = generator(SPE, TIB, 'train', 'valid')\n",
    "\n",
    "print('<--[INFO] creating and compiling model...')\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "accuracy_metric = tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False, name='binary_crossentropy')\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [accuracy_metric, loss])\n",
    "model.summary()\n",
    "print('<--[INFO] training network...')\n",
    "t0 = time()\n",
    "checkpoint_path = \"your-model-saving-path-to-gdrive/model.h5\"\n",
    "stats_path=\"your-csv-saving-path-to-gdrive/model.csv\"\n",
    "my_callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_binary_crossentropy',verbose=1, save_best_only=True, mode='min'),\n",
    "                tf.keras.callbacks.CSVLogger(filename=stats_path,\n",
    "                                             separator=',', append=True),\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', min_delta=0, patience=3, verbose=0, mode=\"min\", baseline=None,\n",
    "                                                 restore_best_weights=True)\n",
    "                ]\n",
    "\n",
    "\n",
    "history=model.fit(\n",
    "        train_gen,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch=SPE,\n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=SPE//5, # Validation set is about 1/5 of training set\n",
    "        callbacks=my_callbacks)\n",
    "t1 = time()\n",
    "print(\"<--[INFO] model was trained in \" + str(round((t1-t0)/60, 1)) + \" minutes\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOaVdzIC32GSM4RWIjtRJeT",
   "collapsed_sections": [],
   "mount_file_id": "1VKDI6QV8NueGImtKHl_jPQ57dwDeBxZm",
   "name": "Αντίγραφο του audio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}